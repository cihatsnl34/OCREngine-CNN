{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9ab49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "521b3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilkleme\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adım 1 - Convolution\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Adım 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2. convolution katmanı\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adım 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adım 4 - YSA\n",
    "classifier.add(Dense(128, activation = 'relu'))\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd3fb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d13003f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 images belonging to 2 classes.\n",
      "Found 17 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# CNN ve resimler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('data/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 1,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('data/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff714b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-0f9963715c65>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  35/2000 [..............................] - ETA: 1:17 - loss: 0.6795 - accuracy: 0.7143WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      "2000/2000 [==============================] - 2s 909us/step - loss: 0.6795 - accuracy: 0.7143 - val_loss: 0.5961 - val_accuracy: 0.7059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b8063e1c0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 2000,\n",
    "                         epochs = 1000,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba61c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\",verbose=1,patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f92b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "   3/2000 [..............................] - ETA: 1:33 - loss: 0.4070 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-eba3e4b83f84>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  34/2000 [..............................] - ETA: 1:17 - loss: 0.6113 - accuracy: 0.7059WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      "2000/2000 [==============================] - 2s 911us/step - loss: 0.6058 - accuracy: 0.7143 - val_loss: 0.6001 - val_accuracy: 0.7059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b80a710d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 2000,\n",
    "                         epochs = 1000,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000,\n",
    "                        verbose = 1,\n",
    "                        callbacks = [earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1103d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c212e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/17 [=======>......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-f223e6cf5bc6>:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred=classifier.predict_generator(test_set,verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "test_set.reset()\n",
    "pred=classifier.predict_generator(test_set,verbose=1)\n",
    "#pred = list(map(round,pred))\n",
    "pred[pred > .5] = 1\n",
    "pred[pred <= .5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "27eab171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[0.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.]\n",
      "[1.]\n",
      "[0.]\n",
      "[0.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.]\n",
      "[1.]\n",
      "test_labels\n",
      "[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#labels = (training_set.class_indices)\n",
    "\n",
    "test_labels = []\n",
    "\n",
    "for i in range(0,int(17)):\n",
    "    test_labels.extend(np.array(test_set[i][1]))\n",
    "    print(test_set[i][1])\n",
    "print('test_labels')\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4bf38833",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosyaisimleri = test_set.filenames\n",
    "#abc = test_set.\n",
    "#print(idx)\n",
    "#test_labels = test_set.\n",
    "sonuc = pd.DataFrame()\n",
    "sonuc['dosyaisimleri']= dosyaisimleri\n",
    "sonuc['tahminler'] = pred\n",
    "sonuc['test'] = test_labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9131fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  5]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, pred)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825ef798",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fc7b06bf5d95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"kerasModel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "classifier.save(\"kerasModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10262367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
